{"pages":[{"title":"九章","text":"Search In a Big Sorted Arrayhttp://www.lintcode.com/problem/search-in-a-big-sorted-array/http://www.jiuzhang.com/solutions/search-in-a-big-sorted-array/","link":"/about/index.html"}],"posts":[{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2020/03/20/hello-world/"},{"title":"Adaboost decision tree algorithms","text":"This is brief introduction of Adaboosting algorithms after I finished the machine learning course in coursera. IntroductionA foundation question in machine learning is: can a set of weak classifiers be combined to create a strong classifier? The answer is yes. Adaboost was the first really successful boosting algorithm developed for binary classification. More importantly, it is so mathematically beautiful and easy to implement that it would definitely be the starting point to learn boosting. In this document, we investigate this algorithm by boosting a set of decision tree algorithms. AnalysisLet’s consider the implementation of Adaboosting ensemble on decision tree model. Given a set of classifiers \\{f_1,f_2,\\cdot, f_k\\}, where $f_i=\\pm 1$ for $i=1,\\cdots, k$ we want to find an appropriate linear combination of these classifiers F_k=\\text{sign}\\sum_{i=1}^kw_i f_isuch that $F_T$ is better that any $f_t$ . How to find these weights: $w_1,\\cdots,w_k$ ? Or even more basically, how to choose these classifiers ${f_1,f_2,\\cdot, f_k}$? Step 1.To begin with, we choose the first classifier $f_1$ to be the usual decision tree model.","link":"/2018/05/14/2018-05-15-Adaboost-decision-tree-algorithms/"},{"title":"Stochastic gradient decent and gradient decent","text":"IntroductionThis analysis explores the relation between the gradient decent and stochastic gradient decent. Starting from the basic gradient decent method, we shall see that SGD actually decrease this energy on “average”. Gradient decent: a math approachLet’s introduce the convex function first. A function $f:\\mathbb{R}^n\\rightarrow\\mathbb{R}$ is convex if and only if for all $x,y$ $\\in \\mathbb{R}^n$ and $\\lambda\\in (0,1)$, we have f(\\lambda x+(1-\\lambda)y)\\leq \\lambda f(x)+(1-\\lambda)f(y). A more mathematical definition is A function is said to be convex if and only if it’s second derivative is always non-negative. A simple example is the parabola equation $x^2$, and as you could see from the graph, this function has a unique minimum. The reason that we restricted our attention on the convex function is because its minimum could be easily calculated. In theory, to get the minimum/maximum of a function, we could simply set the derivative of it to zero and solve the equation(s). However, there are two potential issues here. There may be no closed form for the solutions especially when we have a complicated model. Even there is a explicit formula for the extreme points, the time complexity is $O(n^3)$ , which is another thing we need worry about if we have a super big data set. The gradient decent in machine learning is to find the minimum/maximum of a convex function without calculating the inverse matrix of the derivative. There are many discussions about this context online, here I just take a few lines to talk about the basic idea from the point view of mathematics. Given a convex function ^[The solution may not be converge to the global minimum without convexity.] $f:\\mathbb{R}^n\\rightarrow\\mathbb{R}$, we consider the following ordinary differential equation: \\begin{equation}\\label{eqn:grad}\\frac{dx}{dt}=-\\nabla f,\\quad x\\in \\mathbb{R}^n\\end{equation}.We then look at the change of $f$ along the solution to (\\ref{eqn:grad}), and it turn out that $f$ is monotonicity decreasing along the solution, in fact, the chain rule implies \\begin{equation}\\label{eqn:mono}\\frac{df}{dt}=\\frac{df}{dx}\\cdot \\frac{dx}{dt}=-||\\nabla f||^2.\\end{equation}Therefore, ideally, $f$ should decreases and decreases until it attains a constant. Then the right hand side of (\\ref{eqn:mono}) implies that this constant must be the global minimum. (\\ref{eqn:mono}) also implies that $f$ decreases fastest if we move $x$ in the direction of its negative gradient. The word “fastest” here could be interpreted as “most efficient” somehow, and it basically comes from the fact that the product of two vectors $a,b$ maximize/minimize if and only if $a,b$ are parallel to each other. Another thing should be note here is that there are many other directions that make $f$ decreases, they are just not as efficient as $\\nabla f$ does. This is the foundation of SGD! Gradient descent in regressionRegression is not as mysterious as its name suggest. Mathematically, it’s just an algorithm to solve an optimization problem. Let’s consider the simple case: linear regression. The cost/loss function is defined to be sum square error: \\begin{equation}\\label{eqn:linear}f(w)=||x\\cdot w-y||^2\\end{equation}where $x\\in M^{N\\times n}$ is the feature matrix, $w\\in M^{n\\times 1}$ is the weight vector, and $y\\in M^{N\\times 1}$ is the true value. We want to find a best $w$ that minimize $f$ based on the known observations $(x,y)$. In other words, we just need find the minimum of $f$ . To do this, we simply discretize (\\ref{eqn:mono}) as follows: \\frac{f_{n+1}-f_n}{h}=-||\\nabla f||_n^2,the above expression can be rewritten as a standard iteration form: \\begin{equation}\\label{alg:linear}f_{n+1}=f_n-h\\cdot||\\nabla f||_n^2,\\end{equation}where $h$ is the time step, and $\\nabla f$ can be easily obtained in most regression models, for instance, \\nabla f=-2x^T\\cdot(x\\cdot w-y) where $T$ is representing the transpose. Now if we ignore the numerical instabilities (usually caused by a big step-size $h$), (\\ref{eqn:mono}) implies that $f$ would monotonicity decreasing under (\\ref{alg:linear})! Stochastic descent gradient (SGD)Like gradient descent, SGD is another numerical algorithm to find the minimum/maximum. TBD.","link":"/2018/05/15/2018-05-16-Stochastic-gradient-decent-and-gradient-decent/"},{"title":"Monotonicity of K-means","text":"DescriptionGiven a set $S={x_1,\\cdots,x_n}$ , we aim to (1) partition the $n$ observations into $k(k\\leq n)$ subsets $\\{s_1,\\cdots,s_k\\}$, (2) minimize within-cluster sum of squares. Formally, the objective is to find: \\begin{equation}\\label{eqn:obj}\\underset{s}{\\text{argmin}} \\sum_{i=1}^k\\sum_{x\\in s_i} ||x-c_i||^2\\end{equation}where $c_i$ is the mean (center of mass) of points in the subset $s_i$. Now in order to achieve this goal, the K-means algorithm reads as follows, first, we randomly pick $k$ points $\\{c_1,\\cdots,c_k\\}$ which are called centroids and label those points in $S$ that closer to $c_i$ than any other centroids by $c_i$. Mathematically, we just performed a Voronoi partition on $S$ for the lattice $\\{c_1,\\cdots,c_k\\}$. Next, we want to keep doing this Voronoi partition by updating our lattice so that \\ref{eqn:obj} is monotonously decreasing. There are two steps here: Update the centroid $c_i$ of each cluster by its center of mass, i.e., \\begin{equation}\\label{eqn: centroid}c_i=\\frac{1}{|s_i|}\\sum\\_{x\\in s_i} x;\\end{equation} Update the cluster labels by doing Voronoi partition on the new centroids set $\\{c_i,\\cdots,c_k \\}$. MonotonicityThe monotonicity of K-means algorithm essentially follows from the basic fact that any function attains the extreme points at the points where its derivative is vanishing. In fact, we consider the following energy: \\begin{equation}\\label{eqn:energy}f(c_1,\\cdots,c_k)=\\sum\\_{i=1}^k\\sum\\_{x\\in s_i} ||x-c_i||^2.\\end{equation}The gradient of $f$ with respect to $c_i$ is \\begin{equation}\\label{eqn:grad}\\frac{\\partial f}{\\partial c_i}=-2\\sum\\_{x\\in s_i}(x-c_i),\\quad i=1,\\cdots k.\\end{equation}By pushing (\\ref{eqn:grad}) $=0$ , it’s clear that c_i=\\frac{1}{|s_i|}\\sum_{x\\in s_i} x,which is exactly the centroid we chose in the above updating step. This also implies that K-means is actually a gradient descent algorithm. Unlike the gradient descent we have seen in many other context, here, we have a closed and simple form for the gradient. So we don’t have to implement the algorithm to obtain the gradient but simply use this elegant math formulation (\\ref{eqn: centroid}).","link":"/2018/05/18/2018-05-19-Monotonicity-of-K-means/"}],"tags":[{"name":"Ensemble","slug":"Ensemble","link":"/tags/Ensemble/"},{"name":"Decision Tree","slug":"Decision-Tree","link":"/tags/Decision-Tree/"},{"name":"Stochastic Gradient","slug":"Stochastic-Gradient","link":"/tags/Stochastic-Gradient/"},{"name":"Calculus","slug":"Calculus","link":"/tags/Calculus/"},{"name":"K-means","slug":"K-means","link":"/tags/K-means/"}],"categories":[{"name":"Algorithm","slug":"Algorithm","link":"/categories/Algorithm/"},{"name":"Math","slug":"Algorithm/Math","link":"/categories/Algorithm/Math/"}]}